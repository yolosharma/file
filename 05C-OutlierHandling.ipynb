{"cells":[{"cell_type":"markdown","source":["#### Outlier Handling"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"72c5d3c0-a3ac-4de1-ba97-34c40bd0a958","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# imports\n# hides all warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n# import pandas for spark\nimport pyspark.pandas as ps\n# pandas \nimport pandas as pd\n# numpy\nimport numpy as np"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b6e6c700-433a-4bae-96f9-caaaba78c28b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# outlier handling\n\n# outlier limits\n\"\"\"\nreturns: \n    upper boud & lower bound for array values or df[col] \nusage: \n    OutlierLimits(df[col]): \n\"\"\"\ndef colOutlierLimits(colValues, pMul=3): \n    if (pMul != 3 and pMul != 2.5 and pMul != 2 and pMul != 1.5):\n        pMul = 3\n    pMul = float(pMul)    \n    q1, q3 = np.percentile(colValues, [25, 75])\n    iqr = q3 - q1\n    ll = q1 - (iqr * pMul)\n    ul = q3 + (iqr * pMul)\n    #print(\"Limits:\",q1,q3,iqr,ll,ul)\n    return ll, ul\n\n\n# outlier count for column\n\"\"\"\nreturns: \n    count of outliers in the colName\nusage: \n    colOutCount(colValues)\n\"\"\"\ndef colOutlierCount(colValues, pMul=3):\n    if (pMul != 3 and pMul != 2.5 and pMul != 2 and pMul != 1.5):\n        pMul = 3\n    ll, ul = colOutlierLimits(colValues, pMul)\n    ndOutData = np.where((colValues > ul) | (colValues < ll))\n    ndOutData = np.array(ndOutData)\n    #print(ndOutData)\n    return ndOutData.size\n\n# outlier count for dataframe\n\"\"\"\nreturns: \n    count of outliers in each column of dataframe\nusage: \n    OutlierCount(df): \n\"\"\"\ndef OutlierCount(df, pMul=3): \n    if (pMul != 3 and pMul != 2.5 and pMul != 2 and pMul != 1.5):\n        pMul = 3\n    pMul = float(pMul)    \n    colNames = df.columns\n    #print(colNames)\n    dsRetValue = pd.Series() \n    for colName in colNames:\n        #print(df[colName].dtypes)\n        if (df[colName].dtypes == 'object'):\n            continue\n        #print(colName)\n        colValues = df[colName].values\n        dsRetValue[colName] = colOutlierCount(colValues, pMul)\n    return(dsRetValue)\n\n# oulier index for column\n\"\"\"\nreturns: \n    row index in the colName\nusage: \n    colOutIndex(colValues)\n\"\"\"\ndef colOutlierIndex(colValues, pMul=3):\n    if (pMul != 3 and pMul != 2.5 and pMul != 2 and pMul != 1.5):\n        pMul = 3\n    ll, ul = colOutlierLimits(colValues, pMul)\n    ndOutData = np.where((colValues > ul) | (colValues < ll))\n    ndOutData = np.array(ndOutData)\n    return ndOutData\n\n\n# oulier index for data frame\n\"\"\"\nreturns: \n    row index of outliers in each column of dataframe\nusage: \n    OutlierIndex(df): \n\"\"\"\ndef OutlierIndex(df, pMul=3): \n    if (pMul != 3 and pMul != 2.5 and pMul != 2 and pMul != 1.5):\n        pMul = 3\n    pMul = float(pMul)    \n    colNames = df.columns\n    dsRetValue = pd.Series() \n    for colName in colNames:\n        if (df[colName].dtypes == 'object'):\n            continue\n        colValues = df[colName].values\n        dsRetValue[colName] = str(colOutlierIndex(colValues, pMul))\n    return(dsRetValue)  \n\n# outlier values for column \n\"\"\"\nreturns: \n    actual outliers values in the colName\nusage: \n    colOutValues(colValues)\n\"\"\"\ndef colOutlierValues(colValues, pMul=3):\n    if (pMul != 3 and pMul != 2.5 and pMul != 2 and pMul != 1.5):\n        pMul = 3\n    ll, ul = colOutlierLimits(colValues, pMul)\n    ndOutData = np.where((colValues > ul) | (colValues < ll))\n    ndOutData = np.array(colValues[ndOutData])\n    #ndOutData = np.array(ndOutData)\n    return ndOutData\n\n\n# outlier values for dataframe \n\"\"\"\nreturns: \n    actual of outliers in each column of dataframe\nusage: \n    OutlierValues(df): \n\"\"\"\ndef OutlierValues(df, pMul=3): \n    if (pMul != 3 and pMul != 2.5 and pMul != 2 and pMul != 1.5):\n        pMul = 3\n    pMul = float(pMul)    \n    colNames = df.columns\n    dsRetValue = pd.Series() \n    for colName in colNames:\n        if (df[colName].dtypes == 'object'):\n            continue\n        colValues = df[colName].values\n        dsRetValue[colName] = colOutlierValues(colValues, pMul)\n    return(dsRetValue)\n\n# column level handle outlier by capping\n# at lower limit & upper timit respectively\n\"\"\"\nreturns: \n    array values or df[col].values without any outliers\nusage: \n    HandleOutlier(df[col].values): \n\"\"\"\ndef colHandleOutliers(colValues, pMul=3):\n    ll, ul = colOutlierLimits(colValues, pMul)\n    colValues = np.where(colValues < ll, ll, colValues)\n    colValues = np.where(colValues > ul, ul, colValues)\n    return (colValues)\n\n# data frame level handline outliers\n\"\"\"\ndesc:\n    HandleOutliers - removes Outliers from all cols in df except exclCols \nusage: \n    HandleOutliers(df, colClass) \nparams:\n    df datarame, exclCols - col to ignore while transformation, Multiplier  \n\"\"\"\ndef HandleOutliers(df,  lExclCols=[], pMul=3):\n    #lExclCols = depVars\n    # orig col names\n    colNames = df.columns.to_list()\n    # if not list convert to list\n    if not isinstance(lExclCols, list):\n        lExclCols = [lExclCols]\n    #print(lExclCols)\n    # if not empty, create a dataframe of ExclCols\n    if lExclCols != []:\n        for vExclCol in lExclCols:\n            colNames.remove(vExclCol)\n    # handle outlier for each col\n    for colName in colNames:\n        colValues = df[colName].values\n        if (colOutlierValues(colValues, pMul) > 0):\n            #print(colName)\n            colValues = colHandleOutliers(colValues, pMul)\n            df[colName] = colValues.tolist()\n    return df\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d89e3f1d-117c-4d6e-8bdf-caab28414e3c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# read csv\n\n# File location and type\nfile_location = \"/FileStore/tables/test/outliers.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"true\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location)\n\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a9f4ad1d-e227-4028-82d5-2ff7ff7f530b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# convert dataframe to pandas spark dataframe\npsdf = ps.DataFrame(df)\nprint(psdf.head(5))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"eefd9bfe-aa5b-439c-b733-d14d76ba8d79","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# info\nprint(\"*** Info ***\")\nprint(psdf.info())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d7c98163-cc04-481f-bb9c-3a404c030d23","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# check outlier count\nprint('\\n*** Outlier Count ***')\nprint(OutlierCount(psdf))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"73978b6f-3628-41b8-beb8-afecb7dae255","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# check outlier row index\nprint('\\n*** Outlier Index ***')\nprint(OutlierIndex(psdf))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b517eb00-7895-4ada-b75d-8d1958a12b16","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# check outlier values\nprint('\\n*** Outlier Values ***')\nprint(OutlierValues(psdf))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b9fbb60c-1a6b-4185-9962-915be38fdfa4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# handle outlier \nprint('\\n*** Handle Outliers ***')\nHandleOutliers(psdf)\nprint(\"Done ...\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5750283d-c3fd-47fb-8490-ee4671adf5ce","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# check outlier count\nprint('\\n*** Outlier Count ***')\nprint(OutlierCount(psdf))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c49e935d-fb0a-4943-b398-fbfb29c60442","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# display df\ndisplay(psdf)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d1a02108-9938-4ded-9e8c-d94cb43a8c38","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"05C-OutlierHandling","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
